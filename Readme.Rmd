---
title: "Readme"
author: "Mithun Kondiyara Tilakan"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Data Transformation

This data project has been used as a take-home assignment in the recruitment process for the data engineering positions at Chama.

Chama is a relatively new, modern company, with an IOS App and Android App. To grow our company we must make a special effort in collecting all information available around the App and make it available for everyone in the company. Some information about App usage is generated by our App and our backend API. Other sources of information, like the Google Play Store, can provide very useful insights on App performance and user rating. Chama is very data-oriented and, most decisions are made based on appropriate metrics, therefore, data quality is a must and a concern of everyone involved.

Assignment Some event data come as json files and need some transformation to be structured as tables. Convert the case.json file to 3 csv files, using the programming language of your choice, with the following rules:

CuratedOfferOptions.csv: 
CurationProvider: in quotes 
OfferId: in quotes 
DealerId: in quotes 
UniqueOptionId: in quotes 
OptionId: in quotes 
IsMobileDealer: without quotes 
IsOpen: without quotes Eta: in quotes 
ChamaScore: without quotes 
ProductBrand: in quotes 
IsWinner: without quotes 
MinimumPrice: without quotes 
MaximumPrice: without quotes 
DynamicPrice: without quotes 
FinalPrice: without quotes 
DefeatPrimaryReason: in quotes 
DefeatReasons: in quotes 
EnqueuedTimeSP: DD/MM/YYYY (converted to Brasilian timezone - UTC-3)

DynamicPriceOption.csv: 
Provider: in quotes 
OfferId: in quotes 
UniqueOptionId: in quotes 
BestPrice: without quotes 
EnqueuedTimeSP: DD/MM/YYYY (converted to Brasilian timezone - UTC-3)

DynamicPriceRange.csv: 
Provider: in quotes 
OfferId: in quotes 
MinGlobal: without quotes 
MinRecommended: without quotes 
MaxRecommended: without quotes 
DifferenceMinRecommendMinTheory: without quotes 
EnqueuedTimeSP: DD/MM/YYYY (converted to Brasilian timezone - UTC-3)

Data Description You are given one file data.json. Below is an example of a single record from this file:

{ “EnqueuedTimeUtc”: “2021-09-05 08:04:08 UTC”, “EventName”: “DynamicPrice_Result”, “Payload”: “{"provider":"ApplyDynamicPriceRange","offerId":"a6611d55-9624-4381-8cdd-323ee3689241","algorithmOutput":{"min_global":85.0,"min_recommended":87.2,"max_recommended":97.65,"differenceMinRecommendMinTheory":2.2}}” }

Dataset Credit: stratascratch.com

Solution:

As part of take home assigment, as data transformation project is given.

Task: A json file named data.json is given, from which 3 csv files is to be extracted as

CuratedOfferOptions.csv with 18 columns. DynamicPriceOption.csv with 5 columns. DynamicPriceRange.csv with 7 columns.

Load libraries tidyverse for data transformation and jsonlite to read json file.

```{r}
library(tidyverse)
library(jsonlite)
```

Set working directory to folder where data is saved and create object named ‘url’ to create address for the data file.

Read json file using fromJSON function and save data in object named ‘data’ and clean column names using janitor package function clean_names.

Lets check stucture of data to decide further course of action.

```{r}
setwd("C:/Users/Mithun/Desktop/Git repositories/CHAMA_Data_Transformation")

url<-str_c(getwd(),"/data.json")

data<-fromJSON(url) %>%
        janitor::clean_names()
data

glimpse(data)
```

There are 37 rows and 3 columns in the dataset.

First column is date column which is saved as character data type. This needs to be converted to date time and change timezone to ‘America/Sao Paulo’, as this column is required in final file as UTC-3 timezone.

Second column (event_name) contains one of the 3 desired files. Convert this column to factor.

Third column (payload) is nested json file.

```{r}
data$enqueued_time_utc<-as_datetime(data$enqueued_time_utc)

data$event_name<-factor(data$event_name)

glimpse(data)

data$enqueued_time_utc<-force_tz(data$enqueued_time_utc,"America/Sao_Paulo")
```

Check column names and check factor names in column event_name.

Filter factors and save as different objects as aforementioned below:

CurateOffer_Result: This object contains contents of desired file ‘CuratedOfferOptions.csv’.

DynamicPrice_Result: This object needs to be explored for further contents.

```{r}
colnames(data)

data %>% count(event_name,sort=T)

CurateOffer_Result<-data %>% filter(event_name=="CurateOffer_Result")

DynamicPrice_Result<-data %>% filter(event_name=="DynamicPrice_Result")
```

We use lapply function to unnest data from payload column to extract all desired variables for our first desired file. we keep desired variables and drop others and rename date time variable as desired variable name.

```{r}
CuratedOfferOptions.csv<-CurateOffer_Result %>%
        mutate(extract=lapply(payload,fromJSON)) %>% 
        unnest(extract) %>% 
        unnest(options) %>%
        select(4:20,1) %>% 
        rename(enqueued_time_utc_3="enqueued_time_utc")

CuratedOfferOptions.csv
```

We explore nested json files in object ‘DynamicPrice_Result’ using fromJSON function and lapply iterator. As we read and unnest nested json data frames we find contents of other 2 desired files under the variable ‘provider’. So we filter for desired files , ie , ‘ApplyDynamicPriceRange’ and ‘ApplyDynamicPricePerOption’, select desired columns. As we unnest this time, we use unnest_wider to get contents as columns and not as a single stacked column. We rename datetime column to identify as changed to UTC-3 timezone and save under aforementioned objects:

DynamicPriceRange.csv and DynamicPriceOption.csv

```{r}
DynamicPrice_Result.csv<-DynamicPrice_Result %>% 
        mutate(extract=lapply(payload,fromJSON)) %>% 
        unnest_wider(extract) 

DynamicPrice_Result.csv

DynamicPrice_Result.csv %>% count(provider,sort=T)

DynamicPriceRange.csv<-DynamicPrice_Result.csv %>% 
        filter(provider=="ApplyDynamicPriceRange") %>% 
        select(4:6,1) %>%
        unnest_wider(algorithmOutput) %>% 
        rename(enqueued_time_utc_3="enqueued_time_utc")

DynamicPriceRange.csv

DynamicPriceOption.csv<-DynamicPrice_Result.csv %>% 
        filter(provider=="ApplyDynamicPricePerOption") %>% 
        select(4:6,1) %>% 
        unnest_wider(algorithmOutput) %>% 
        unnest(uniqueOptionId) %>% 
        unnest(bestPrice) %>% 
        rename(enqueued_time_utc_3="enqueued_time_utc")

DynamicPriceOption.csv
```
Finally write objects as desired file names using write_csv function.

```{r}
write_csv(DynamicPriceRange.csv,"DynamicPriceRange.csv")
write_csv(DynamicPriceOption.csv,"DynamicPriceOption.csv")
write_csv(CuratedOfferOptions.csv,"CuratedOfferOptions.csv")
```

